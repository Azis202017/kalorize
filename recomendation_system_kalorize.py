# -*- coding: utf-8 -*-
"""Recomendation System Kalorize

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kozxAUQY4ReJX5QrmvYuGA3BbYha8Xwn
"""

!pip install -q tensorflow-recommenders
!pip install -q --upgrade tensorflow-datasets
!pip install -q scann

import os
import pprint
import tempfile

from typing import Dict, Text

import numpy as np
import tensorflow as tf
import tensorflow_datasets as tfds
import tensorflow_recommenders as tfrs
from sklearn import preprocessing
from sklearn.preprocessing import MinMaxScaler
from sklearn.neighbors import NearestNeighbors
import html
# pd.set_option('display.max_columns', None)
# pd.set_option('display.max_rows', None)
# pd.set_option('display.expand_frame_repr', False)

from google.colab import files

# Mengunggah file dari komputer lokal ke Colab
uploaded = files.upload()

# Menampilkan informasi tentang file yang diunggah
for filename in uploaded.keys():
    print(f'File {filename} berhasil diunggah dengan ukuran {len(uploaded[filename])} bytes')

import pandas as pd

# Replace 'your_file.xlsx' with the actual file path of your Excel file.
df = pd.read_excel('cleaned_recipes.xlsx')
df

columns = df.columns.values
columns

df.isna().sum()

# simple preprocess df['nama']
df['nama'] = df['nama'].apply(html.unescape)

"""# Features Kalorize and KNN Prediction"""

df_copy = df.copy()

df_features = df.iloc[:, 2:4]
min_max_scaler = MinMaxScaler()
df_features = min_max_scaler.fit_transform(df_features)
all_calories = list(df['kalori'].values)

model = NearestNeighbors(n_neighbors=10, algorithm='ball_tree').fit(df_features)
# KNN return 2 array yaitu distances dan indices
indices = model.kneighbors(df_features, return_distance=False)

def closest(all_calories, input):
    return all_calories[min(range(len(all_calories)), key=lambda i: abs(all_calories[i]-input))]

def calculate_bmr(gender, weight, height, age):
    if gender == 'male':
        bmr = 10 * weight + 6.25 * height - 5 * age + 5
    elif gender == 'female':
        bmr = 10 * weight + 6.25 * height - 5 * age - 161
    else:
        raise ValueError("Invalid gender. Please choose 'male' or 'female'.")
    return bmr

def calculate_total_calories(bmr, activity_level, target):
    activity_levels = {
        'easy': 1.375,
        'medium': 1.55,
        'hard': 1.725,
        'extreme': 1.9
    }
    targets = {
        'reduce_weight': 0.8,
        'increase_muscle': 1.2,
        'be_healthy': 1
    }
    maintain_calories = bmr * activity_levels[activity_level]
    total_calories = maintain_calories * targets[target]
    return total_calories

def recommendation(gender, weight, height, age, activity_level, target):
    bmr = calculate_bmr(gender, weight, height, age)
    total_calories = calculate_total_calories(bmr, activity_level, target)

    breakfast_calories = total_calories * 0.35
    lunch_calories = total_calories * 0.40
    dinner_calories = total_calories * 0.25

    breakfast_closest_food = closest(all_calories, breakfast_calories)
    lunch_calories_food = closest(all_calories, lunch_calories)
    dinner_calories_food = closest(all_calories, lunch_calories)

    breakfast_food_code = all_calories.index(breakfast_closest_food)
    lunch_food_code = all_calories.index(lunch_calories_food)
    dinner_food_code = all_calories.index(dinner_calories_food)

    breakfast_similarity = df.iloc[indices[breakfast_food_code]]
    lunch_similarity = df.iloc[indices[lunch_food_code]]
    dinner_similarity = df.iloc[indices[dinner_food_code]]

    return breakfast_similarity, lunch_similarity, dinner_similarity

gender = 'male'
weight = 52
height = 169
age = 20
activity_level = 'medium'
target = 'reduce_weight'

breakfast, lunch, dinner = recommendation(
    gender, weight, height, age, activity_level, target)

print(breakfast)
print(lunch)
print(dinner)

"""# Data Using Tensorflow"""

food_data = tf.data.Dataset.from_tensor_slices({
    "id_makanan": df["id_makanan"].values,
    "nama": df["nama"].values,
})

food_ingridient = tf.data.Dataset.from_tensor_slices({
    "nama": df["nama"].values,
    "kalori": df["kalori"].values,
    "protein": df["protein"].values,
    'bahan': df['bahan'].values,
    'cooking_step': df['cooking_step'].values
})

food_name = tf.data.Dataset.from_tensor_slices({
    "nama": df["nama"].values,
})

tf.random.set_seed(42)
shuffled = food_data.shuffle(100_000, seed=42, reshuffle_each_iteration=False)

train = food_data.take(80_000)
test = food_data.skip(80_000).take(20_000)

food_titles = food_name.batch(1_000)
food_titles_arrays = food_titles.map(lambda x: x['nama'])

food_ids = food_data.batch(1_000_000).map(lambda x: x["id_makanan"])
food_ids_np = np.array([x.numpy().tolist() for x in food_ids])
unique_food_titles = np.unique(np.concatenate(list(food_titles_arrays)))
unique_food_ids = np.unique(np.concatenate(list(food_ids)))
unique_food_ids = [str(id) for id in unique_food_ids]

unique_food_titles[:10]

"""# Model"""

embedding_dimension = 32

food_model = tf.keras.Sequential([
  tf.keras.layers.StringLookup(
      vocabulary=unique_food_ids, mask_token=None),
  # We add an additional embedding to account for unknown tokens.
  tf.keras.layers.Embedding(len(unique_food_ids) + 1, embedding_dimension)
])

food_name_model = tf.keras.Sequential([
  tf.keras.layers.StringLookup(
      vocabulary=unique_food_titles, mask_token=None),
  tf.keras.layers.Embedding(len(unique_food_titles) + 1, embedding_dimension)
])

metrics = tfrs.metrics.FactorizedTopK(
  candidates=food_titles_arrays.batch(128).map(food_name_model)
)

task = tfrs.tasks.Retrieval(
  metrics=metrics
)

class FoodslensModel(tfrs.Model):

  def __init__(self, food_model, food_name_model):
    super().__init__()
    self.food_name_model: tf.keras.Model = food_name_model
    self.food_model: tf.keras.Model = food_model
    self.task: tf.keras.layers.Layer = task

  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:
    # We pick out the user features and pass them into the user model.
    user_embeddings = self.food_model(features["id_makanan"])
    # And pick out the movie features and pass them into the movie model,
    # getting embeddings back.
    positive_movie_embeddings = self.food_name_model(features["nama"])

    # The task computes the loss and the metrics.
    return self.task(user_embeddings, positive_movie_embeddings)

class NoBaseClassFoodlensModel(tf.keras.Model):

  def __init__(self, food_model, food_name_model):
    super().__init__()
    self.food_name_model: tf.keras.Model = food_name_model
    self.food_model: tf.keras.Model = food_model
    self.task: tf.keras.layers.Layer = task

  def train_step(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:

    # Set up a gradient tape to record gradients.
    with tf.GradientTape() as tape:

      # Loss computation.
      user_embeddings = self.food_model(features["id_makanan"])
      positive_movie_embeddings = self.food_name_model(features["nama"])
      loss = self.task(user_embeddings, positive_movie_embeddings)

      # Handle regularization losses as well.
      regularization_loss = sum(self.losses)

      total_loss = loss + regularization_loss

    gradients = tape.gradient(total_loss, self.trainable_variables)
    self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))

    metrics = {metric.name: metric.result() for metric in self.metrics}
    metrics["loss"] = loss
    metrics["regularization_loss"] = regularization_loss
    metrics["total_loss"] = total_loss

    return metrics

  def test_step(self, features: Dict[Text, tf.Tensor]) -> tf.Tensor:

    # Loss computation.
    user_embeddings = self.food_model(features["id_makanan"])
    positive_movie_embeddings = self.food_name_model(features["nama"])
    loss = self.task(user_embeddings, positive_movie_embeddings)

    # Handle regularization losses as well.
    regularization_loss = sum(self.losses)

    total_loss = loss + regularization_loss

    metrics = {metric.name: metric.result() for metric in self.metrics}
    metrics["loss"] = loss
    metrics["regularization_loss"] = regularization_loss
    metrics["total_loss"] = total_loss

    return metrics

model = FoodslensModel(food_model, food_name_model)
model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))

cached_train = train.shuffle(100_000).batch(8192).cache()
cached_test = test.batch(4096).cache()